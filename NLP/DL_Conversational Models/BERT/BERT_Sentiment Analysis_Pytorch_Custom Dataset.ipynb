{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Sentiment Analysis_Pytorch_Custom Dataset.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2fb642bcced148c1be1b8c8709d1adfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae0d5d354c55489fa10f1b7117ad0893","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_303c27b1e7824e498a1ee3c5a4b31ac4","IPY_MODEL_c9499c69bbd74fa79b46cf9d8415f07c"]}},"ae0d5d354c55489fa10f1b7117ad0893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"303c27b1e7824e498a1ee3c5a4b31ac4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d6d8bd49e2c949ad93bbd5b9200aa915","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_137d60010f65481699bb00c295f769ee"}},"c9499c69bbd74fa79b46cf9d8415f07c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9b7c73c6da740dabfebce39c0b97a6d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:08&lt;00:00, 52.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49d4050f4ee44c7ba6d8b3b2fc3640af"}},"d6d8bd49e2c949ad93bbd5b9200aa915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"137d60010f65481699bb00c295f769ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9b7c73c6da740dabfebce39c0b97a6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"49d4050f4ee44c7ba6d8b3b2fc3640af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9851d6a734e94b41822b243028928ab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_02a4f30bf45f4af698eca32d4386ce5e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee8ff3e7f4cd4f2f888fba4684f8ef8c","IPY_MODEL_ebddf4fbbc8e4ef9b559f98d4b1a68ae"]}},"02a4f30bf45f4af698eca32d4386ce5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee8ff3e7f4cd4f2f888fba4684f8ef8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e0951579a2c4a8691a80aa28b61a111","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30f832aedc7e4e48af36d6b6ac158c17"}},"ebddf4fbbc8e4ef9b559f98d4b1a68ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b3d8bc9333bf4a1aa164c641bb71fae6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:07&lt;00:00, 57.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_836fa469ecce40729af09efa8ad4105a"}},"1e0951579a2c4a8691a80aa28b61a111":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30f832aedc7e4e48af36d6b6ac158c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3d8bc9333bf4a1aa164c641bb71fae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"836fa469ecce40729af09efa8ad4105a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"DaRUvf4NI-T3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615908772216,"user_tz":-330,"elapsed":743,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"202383cd-340b-4fb3-b032-4247ff49dece"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxH0ZaclqfcS","executionInfo":{"status":"ok","timestamp":1615908773598,"user_tz":-330,"elapsed":786,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"343ef8bd-a877-471b-82c6-d6cd65f36744"},"source":["%cd '/content/drive/My Drive/Seq2Seq/BERT/Data'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Seq2Seq/BERT/Data\n","model.h5  __pycache__  test.csv  tokenization.py  train.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rOffcIu0O0a8"},"source":["import torch\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.model_selection import train_test_split\n","import torchtext\n","#from torchtext.data import Field,BucketIterator,TabularDataset\n","from torchtext.legacy.data import Field,BucketIterator,TabularDataset\n","\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-j2_vHLLRtbx","executionInfo":{"status":"ok","timestamp":1615908779176,"user_tz":-330,"elapsed":3461,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"243e3cce-c99d-4d94-9a25-b95423267f4e"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hTbiisI-PzRX"},"source":["Data Loading:\n","\n","Dataset containing a set of sentences with labels 0 and 1 \n","(1 carrying negaitive sense and 0 carrying positive sense)"]},{"cell_type":"code","metadata":{"id":"I8DxE6Q6cPhN"},"source":["# Loading data\n","\n","train = pd.read_csv(\"/content/drive/My Drive/Seq2Seq/BERT/Data/train.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/Seq2Seq/BERT/Data/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"W_7CY6mSOz-V","executionInfo":{"status":"ok","timestamp":1615908782952,"user_tz":-330,"elapsed":631,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"aef2dc01-9a00-4e1a-cbae-684d59c0465d"},"source":["train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he is being put on a stretcher do not want to ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>emergency units simulate a chemical explosion ...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>us national park services tonto national fores...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bestnaijamade yr old pkk suicide bomber who de...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>russian ushanka winter military fur hat xl wit...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text target\n","0  he is being put on a stretcher do not want to ...    pos\n","1  emergency units simulate a chemical explosion ...    neg\n","2  us national park services tonto national fores...    pos\n","3  bestnaijamade yr old pkk suicide bomber who de...    neg\n","4  russian ushanka winter military fur hat xl wit...    pos"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iGSSl7rnJik","executionInfo":{"status":"ok","timestamp":1615908784372,"user_tz":-330,"elapsed":753,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"c3d7e8e7-cadb-44a7-dc9b-f87988839374"},"source":["train.target.unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['pos', 'neg'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"Mnhmwrv0plqX"},"source":["train['target'] = train['target'].replace([1],'neg')\n","train['target'] = train['target'].replace([0],'pos')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4-GhSNeYqGqf","executionInfo":{"status":"ok","timestamp":1615908787277,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"2472dd30-46e8-4b1f-9ef0-e8d149f5d128"},"source":["train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he is being put on a stretcher do not want to ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>emergency units simulate a chemical explosion ...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>us national park services tonto national fores...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bestnaijamade yr old pkk suicide bomber who de...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>russian ushanka winter military fur hat xl wit...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text target\n","0  he is being put on a stretcher do not want to ...    pos\n","1  emergency units simulate a chemical explosion ...    neg\n","2  us national park services tonto national fores...    pos\n","3  bestnaijamade yr old pkk suicide bomber who de...    neg\n","4  russian ushanka winter military fur hat xl wit...    pos"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"tPTFowoKXOIy"},"source":["# replacing contraction words\n","\n","contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",'i\\'m':'i am', \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"irO9o9AOXN5h"},"source":["# dealing with spl characters\n","punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';',  '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n"," '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n"," '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n"," '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n"," '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√','∞','θ','÷','α','•','à','−','β','∅','³','π','‘','₹','´','°','™','√²','—–' ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"naVVyp_0XNvB"},"source":["punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TA0BgX1DX2u_"},"source":["Preprocessing Functions"]},{"cell_type":"code","metadata":{"id":"t1dnlqh8XrZ5"},"source":["def clean_contractions(text, mapping):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","    text = ' '.join([mapping[t] if t in mapping else mapping[t.lower()] if t.lower() in mapping else t for t in text.split(\" \")])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kh0XlcFSXrWu"},"source":["def clean_special_chars(text, punct, mapping):\n","    for p in mapping:\n","        text = text.replace(p, mapping[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, '')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ', '\\ufeff': ''}  # to be updated again upon checking the coverage\n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmROhJkQXrTz"},"source":["def remove_newlines(sent):\n","  sent = re.sub(r'\\s+', \" \", sent )\n","  return sent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BShTD9rqXrQd"},"source":["def clean_numbers(x):\n","    if bool(re.search(r'\\d', x)):\n","        x = re.sub('[0-9]{5,}', '#####', x)\n","        x = re.sub('[0-9]{4}', '####', x)\n","        x = re.sub('[0-9]{3}', '###', x)\n","        x = re.sub('[0-9]{2}', '##', x)\n","        #x = re.sub('[0-9]', '#', x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AV6RN3gLYbyj"},"source":["Data Cleansing Activities"]},{"cell_type":"code","metadata":{"id":"ERMNE7k8XrNG"},"source":["train['text'] = train['text'].apply(lambda x: clean_contractions(x, contraction_mapping))\n","test['text'] = test['text'].apply(lambda x: clean_contractions(x, contraction_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rysH4PWIXrKC"},"source":["train['text'] = train['text'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n","test['text'] = test['text'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmO7UguoY0ra"},"source":["train['text'] = train['text'].apply(lambda x: clean_contractions(x, contraction_mapping))\n","test['text'] = test['text'].apply(lambda x: clean_contractions(x, contraction_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Htt8tUfgY0o5"},"source":["train['text'] = train['text'].apply(lambda x : x.lower())\n","test['text'] = test['text'].apply(lambda x : x.lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJj3CQMrZCeF"},"source":["train['text'] = train['text'].apply(lambda x : remove_newlines(x))\n","test['text'] = test['text'].apply(lambda x : remove_newlines(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28cch4qyZCap"},"source":["train['text'] = train['text'].apply(lambda x: clean_numbers(x))\n","test['text'] = test['text'].apply(lambda x: clean_numbers(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Ssnn_fY0l9"},"source":["train['text'] = train['text'].apply(lambda x: clean_numbers(x))\n","test['text'] = test['text'].apply(lambda x: clean_numbers(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"TE64GiUDY0iu","executionInfo":{"status":"ok","timestamp":1615908811439,"user_tz":-330,"elapsed":2171,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"9187037e-c5b8-4190-9800-4450e815ba9f"},"source":["train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he is being put on a stretcher do not want to ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>emergency units simulate a chemical explosion ...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>us national park services tonto national fores...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bestnaijamade yr old pkk suicide bomber who de...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>russian ushanka winter military fur hat xl wit...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text target\n","0  he is being put on a stretcher do not want to ...    pos\n","1  emergency units simulate a chemical explosion ...    neg\n","2  us national park services tonto national fores...    pos\n","3  bestnaijamade yr old pkk suicide bomber who de...    neg\n","4  russian ushanka winter military fur hat xl wit...    pos"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"HEmWwnwEV8T6"},"source":["Data cleansing"]},{"cell_type":"code","metadata":{"id":"eJLsmniFO0Wm"},"source":["# Loading pretrained BERT tokenizer\n","\n","import transformers\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gshSthpPO0T5","executionInfo":{"status":"ok","timestamp":1615908815609,"user_tz":-330,"elapsed":882,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"f64a0ecd-af1a-4f8d-b156-98aaf9b7482f"},"source":["# The tokenizer has a vocab attribute which contains the actual vocabulary\n","\n","len(tokenizer.vocab)  #size of the vocabulary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30522"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXtb1y4FO0Q7","executionInfo":{"status":"ok","timestamp":1615908816868,"user_tz":-330,"elapsed":606,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"6ddda75f-63e0-40e6-8760-9e9827a34ad3"},"source":["# Special tokens\n","\n","init_token = tokenizer.cls_token  \n","eos_token = tokenizer.sep_token\n","pad_token = tokenizer.pad_token\n","unk_token = tokenizer.unk_token\n","\n","print(init_token, eos_token, pad_token, unk_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] [SEP] [PAD] [UNK]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1lsJ2ZEO0OD","executionInfo":{"status":"ok","timestamp":1615908818260,"user_tz":-330,"elapsed":639,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"fcdab5de-6a16-4776-ff27-5f4add7c956f"},"source":["# Indexes of the special tokens:\n","\n","init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n","eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n","pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n","unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n","\n","print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["101 102 0 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlj8td9dO0K4","executionInfo":{"status":"ok","timestamp":1615908819937,"user_tz":-330,"elapsed":1104,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"00282af8-e8c1-40c7-c685-635b4d8bec4c"},"source":["# The pretrained BERT model was trained on sequences with a defined maximum length \n","#it does not know how to handle sequences longer than it has been trained on. \n","# Getting the maximum length of these input size for the version of the transformer being used:\n","\n","max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n","\n","print(max_input_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["512\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FtXfbLl9O0H1"},"source":["# Funtion to handle tokenisation of sentences:\n","\n","def tokenize_and_cut(sentence):\n","    tokens = tokenizer.tokenize(sentence) \n","    tokens = tokens[:max_input_length-2]\n","    return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkqWpXNkO0FM"},"source":["from torchtext.legacy import data\n","\n","TEXT = data.Field(batch_first = True,\n","                  use_vocab = False,\n","                  tokenize = tokenize_and_cut,\n","                  preprocessing = tokenizer.convert_tokens_to_ids,\n","                  init_token = init_token_idx,\n","                  eos_token = eos_token_idx,\n","                  pad_token = pad_token_idx,\n","                  unk_token = unk_token_idx)\n","\n","LABEL = data.LabelField(dtype = torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfyHnqeoO0CW"},"source":["# Splitting the cleansed training dataset into train and validation sets\n","\n","train_data , valid_data = train_test_split(train,test_size = 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"AYdOozgpamb-","executionInfo":{"status":"ok","timestamp":1615908831563,"user_tz":-330,"elapsed":925,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"3e5b7594-5937-471e-cdda-5f54d14d0250"},"source":["train_data.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3763</th>\n","      <td>ouvindo peace love amp armageddon</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                   text target\n","3763  ouvindo peace love amp armageddon    pos"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VWH3_ZejVUFo","executionInfo":{"status":"ok","timestamp":1615908834194,"user_tz":-330,"elapsed":843,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"b0375f1e-4948-47a0-ad07-2a208f1444ac"},"source":["%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Seq2Seq/BERT/Data'"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"FX1olXjYaXiu"},"source":["train_data.to_csv('train.csv',index = False)\n","valid_data.to_csv('test.csv',index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_Y4hTlDaj1k"},"source":["data_fields = [('text',TEXT),('label',LABEL)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZlGsU00Ja0uM"},"source":["# TabularDataset(Dataset):Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n","# Create a TabularDataset given a path, file format, and field list\n","\n","train_data , valid_data = TabularDataset.splits(path ='/content/drive/My Drive/Seq2Seq/BERT/Data' ,train='train.csv', test ='test.csv', format='csv', fields=data_fields)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNewJ5Cyi8L6","executionInfo":{"status":"ok","timestamp":1615908844236,"user_tz":-330,"elapsed":584,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"3f1ea38c-eace-4498-bbdc-a5c3a618496c"},"source":["print(f\"Number of training examples: {len(train_data)}\")\n","print(f\"Number of testing examples: {len(valid_data)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of training examples: 3898\n","Number of testing examples: 976\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIij88A0jPPQ","executionInfo":{"status":"ok","timestamp":1615908846146,"user_tz":-330,"elapsed":934,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"f783bbac-fe16-436c-c5c8-15656bafc63d"},"source":["print(vars(train_data.examples[11]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'text': [10047, 5458, 1997, 2035, 2122, 2035, 3669, 6961, 18900, 3334, 2111, 2027, 2069, 2360, 2023, 2000, 4315, 12502, 2304, 3669, 6961, 18900, 3334, 2027, 2123, 2102, 2079, 2505, 2005, 1005, 2035, 3268, 1005, 1048, 2213, 7011, 2080], 'label': 'pos'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OcQRwfKNqh9L"},"source":["# building vocabulary for the data labels\n","LABEL.build_vocab(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2MRKLWpjdoB"},"source":["from torchtext.legacy.data import BucketIterator,TabularDataset\n","\n","BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data), \n","    batch_size = BATCH_SIZE, \n","    device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAWGkEgzj_4z"},"source":["Building the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["2fb642bcced148c1be1b8c8709d1adfd","ae0d5d354c55489fa10f1b7117ad0893","303c27b1e7824e498a1ee3c5a4b31ac4","c9499c69bbd74fa79b46cf9d8415f07c","d6d8bd49e2c949ad93bbd5b9200aa915","137d60010f65481699bb00c295f769ee","e9b7c73c6da740dabfebce39c0b97a6d","49d4050f4ee44c7ba6d8b3b2fc3640af","9851d6a734e94b41822b243028928ab3","02a4f30bf45f4af698eca32d4386ce5e","ee8ff3e7f4cd4f2f888fba4684f8ef8c","ebddf4fbbc8e4ef9b559f98d4b1a68ae","1e0951579a2c4a8691a80aa28b61a111","30f832aedc7e4e48af36d6b6ac158c17","b3d8bc9333bf4a1aa164c641bb71fae6","836fa469ecce40729af09efa8ad4105a"]},"id":"Au8eEFkgj4fo","executionInfo":{"status":"ok","timestamp":1615908888636,"user_tz":-330,"elapsed":11907,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"cbd52695-6b57-4eef-a4a3-87c7ebcdf81c"},"source":["from transformers import BertTokenizer, BertModel\n","\n","bert = BertModel.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fb642bcced148c1be1b8c8709d1adfd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9851d6a734e94b41822b243028928ab3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mc93YNt4kEyj"},"source":["import torch.nn as nn\n","\n","class BERTGRUSentiment(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_dim,\n","                 output_dim,\n","                 n_layers,\n","                 bidirectional,\n","                 dropout):\n","        \n","        super().__init__()\n","        \n","        self.bert = bert\n","        \n","        embedding_dim = bert.config.to_dict()['hidden_size']\n","        \n","        self.rnn = nn.GRU(embedding_dim,\n","                          hidden_dim,\n","                          num_layers = n_layers,\n","                          bidirectional = bidirectional,\n","                          batch_first = True,\n","                          dropout = 0 if n_layers < 2 else dropout)\n","        \n","        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        \n","        #text = [batch size, sent len]\n","                \n","        with torch.no_grad():\n","            embedded = self.bert(text)[0]\n","                \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        _, hidden = self.rnn(embedded)\n","        \n","        #hidden = [n layers * n directions, batch size, emb dim]\n","        \n","        if self.rnn.bidirectional:\n","            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        else:\n","            hidden = self.dropout(hidden[-1,:,:])\n","                \n","        #hidden = [batch size, hid dim]\n","        \n","        output = self.out(hidden)\n","        \n","        #output = [batch size, out dim]\n","        \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DL0FPUykOY7"},"source":["# Creating an instance of our model\n","\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.25\n","\n","model = BERTGRUSentiment(bert,\n","                         HIDDEN_DIM,\n","                         OUTPUT_DIM,\n","                         N_LAYERS,\n","                         BIDIRECTIONAL,\n","                         DROPOUT)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hj87aPWmkSrp","executionInfo":{"status":"ok","timestamp":1615908894944,"user_tz":-330,"elapsed":626,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"7dac7fa0-e2ad-498e-fc05-d7d1b6596fb1"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The model has 112,241,409 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ARuNnOmrkki1"},"source":["# In order to freeze paramers we need to set their requires_grad attribute to False\n","\n","for name, param in model.named_parameters():                \n","    if name.startswith('bert'):\n","        param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywJuk_R6kyrP","executionInfo":{"status":"ok","timestamp":1615908900220,"user_tz":-330,"elapsed":1014,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"13158469-3b17-4baf-8102-708691d8d893"},"source":["def count_parameters(model):  # Counting total number of trainable parameters\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The model has 2,759,169 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4C9pXDyBk8dE","executionInfo":{"status":"ok","timestamp":1615908901412,"user_tz":-330,"elapsed":518,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"081ba735-d98d-4948-d511-8915b4449631"},"source":["# Checking names of the trainable parameters:\n","\n","for name, param in model.named_parameters():                \n","    if param.requires_grad:\n","        print(name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rnn.weight_ih_l0\n","rnn.weight_hh_l0\n","rnn.bias_ih_l0\n","rnn.bias_hh_l0\n","rnn.weight_ih_l0_reverse\n","rnn.weight_hh_l0_reverse\n","rnn.bias_ih_l0_reverse\n","rnn.bias_hh_l0_reverse\n","rnn.weight_ih_l1\n","rnn.weight_hh_l1\n","rnn.bias_ih_l1\n","rnn.bias_hh_l1\n","rnn.weight_ih_l1_reverse\n","rnn.weight_hh_l1_reverse\n","rnn.bias_ih_l1_reverse\n","rnn.bias_hh_l1_reverse\n","out.weight\n","out.bias\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VJ8y69hNlUU_"},"source":["Training the Model"]},{"cell_type":"code","metadata":{"id":"IwOrP4lolOPR"},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pqb90L3TlX0N"},"source":["criterion = nn.BCEWithLogitsLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RGYZ7_nlato"},"source":["# Placing the model and criterion onto the GPU (if available)\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pz8n-u98lj4Q"},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUIjID-xl2Q4"},"source":["Defining functions for: calculating accuracy, performing a training epoch, performing an evaluation epoch and calculating how long a training/evaluation epoch takes"]},{"cell_type":"code","metadata":{"id":"bLnfssB2l11r"},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00cJum2ol1yZ"},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuwjMOdDl1u4"},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oWycYVnl1sO"},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oInbfrghmYSk"},"source":["Training the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQk1sd7Ml1ov","executionInfo":{"status":"ok","timestamp":1615909540017,"user_tz":-330,"elapsed":343706,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"bc3b3899-756e-4448-f015-f9d38fe8313b"},"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","            \n","    end_time = time.time()\n","        \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","        \n","    torch.save(model.state_dict(), 'tut6-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 6s\n","\tTrain Loss: 0.404 | Train Acc: 82.61%\n","Epoch: 02 | Epoch Time: 1m 7s\n","\tTrain Loss: 0.373 | Train Acc: 83.66%\n","Epoch: 03 | Epoch Time: 1m 7s\n","\tTrain Loss: 0.353 | Train Acc: 85.23%\n","Epoch: 04 | Epoch Time: 1m 6s\n","\tTrain Loss: 0.342 | Train Acc: 85.37%\n","Epoch: 05 | Epoch Time: 1m 7s\n","\tTrain Loss: 0.310 | Train Acc: 86.87%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N4vn31VfvD4T"},"source":["Inference"]},{"cell_type":"code","metadata":{"id":"v2nUIFyql1h_"},"source":["def predict_sentiment(model, tokenizer, sentence):\n","    model.eval()\n","    tokens = tokenizer.tokenize(sentence)\n","    tokens = tokens[:max_input_length-2]\n","    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(0)\n","    prediction = torch.sigmoid(model(tensor))\n","    return prediction.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZQoVUZPl1bm","executionInfo":{"status":"ok","timestamp":1615909944986,"user_tz":-330,"elapsed":761,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"}},"outputId":"c1930d04-4f0c-4138-ab17-de6e45b84810"},"source":["predict_sentiment(model, tokenizer, \"This film is great\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1056985929608345"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"G6jmzpa7l1YL"},"source":[""],"execution_count":null,"outputs":[]}]}