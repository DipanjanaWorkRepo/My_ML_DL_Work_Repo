{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"BERT_Fine Tuned Model_for_Classification Task_with_Kaggle Dataset_Keras.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DaRUvf4NI-T3","executionInfo":{"elapsed":30547,"status":"ok","timestamp":1618395047138,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"},"user_tz":-330},"outputId":"ccbaa254-dae2-400a-e541-d2b525bac834"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxH0ZaclqfcS","executionInfo":{"elapsed":3412,"status":"ok","timestamp":1618395051831,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"},"user_tz":-330},"outputId":"6b7c8753-cdac-44cf-89c4-7ed6901091a1"},"source":["%cd '/content/drive/My Drive/Seq2Seq/BERT/Data'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Seq2Seq/BERT/Data\n","model.h5  __pycache__  test.csv  tokenization.py  train.csv  tut6-model.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tdJBGHOecOxQ"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzXD658QcPty"},"source":["# Getting BERT Tokeniser\n","\n","!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-XAWSyYdrHp","outputId":"eedea1a8-5574-419f-e8ee-107c71564a7e"},"source":["!pip install bert-for-tf2\n","!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=76ac2b50bb7facc797ebe6b4b6f2ea22d1325c169068405cccfcec40f10f1b72\n","  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=861cd0ff17dd547d77ed160ee24ee234b0e0f86ca228f26e6f2023dd6dbe0b15\n","  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=86dfb2940ee5735e335cb4814f9a25fff900cb745fa15d8e74cbd300fc9f0af6\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 6.3MB/s \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sh78dBThdyWD"},"source":["try:\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","\n","from tensorflow.keras import layers\n","import bert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"LlthUFttcPql"},"source":["import tokenization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3gkJ1Xmd8w5"},"source":["Helper Functions"]},{"cell_type":"code","metadata":{"id":"jJndYtlhcPoY"},"source":["def bert_encode(texts, tokenizer, max_len=512):\n","    all_tokens = []\n","    all_masks = []\n","    all_segments = []\n","    \n","    for text in texts:\n","        text = tokenizer.tokenize(text)\n","            \n","        text = text[:max_len-2]\n","        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n","        pad_len = max_len - len(input_sequence)\n","        \n","        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n","        tokens += [0] * pad_len\n","        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n","        segment_ids = [0] * max_len\n","        \n","        all_tokens.append(tokens)\n","        all_masks.append(pad_masks)\n","        all_segments.append(segment_ids)\n","    \n","    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ynEs_naScPlf"},"source":["def build_model(bert_layer, max_len=512):\n","    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","\n","    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    clf_output = sequence_output[:, 0, :]\n","    out = Dense(1, activation='sigmoid')(clf_output)\n","    \n","    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FH4nfjK6eVSJ"},"source":["Loading BERT from the Tensorflow Hub:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hL8GvBZ-cPjW","executionInfo":{"elapsed":40582,"status":"ok","timestamp":1615875047080,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"6560c72f-fc92-444d-f56a-768788821e9d"},"source":["%%time\n","module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n","bert_layer = hub.KerasLayer(module_url, trainable=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 22.5 s, sys: 5.29 s, total: 27.8 s\n","Wall time: 29.2 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8DxE6Q6cPhN"},"source":["# Loading data\n","\n","train = pd.read_csv(\"/content/drive/My Drive/Seq2Seq/BERT/Data/train.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/Seq2Seq/BERT/Data/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"znf3LbWygKO1","executionInfo":{"elapsed":40519,"status":"ok","timestamp":1615875047407,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"0f17d887-f98f-43dc-f2fb-48616e2f1b5e"},"source":["train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id keyword  ...                                               text target\n","0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n","1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n","2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n","3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n","4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"LyzM1AHhcPdd"},"source":["# Loading tokenizer from the bert layer:\n","\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M95_LnaacPav"},"source":["# Encoding the text into tokens, masks, and segment flags:\n","\n","train_input = bert_encode(train.text.values, tokenizer, max_len=160)\n","test_input = bert_encode(test.text.values, tokenizer, max_len=160)\n","train_labels = train.target.values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LPLehRPvf5qa"},"source":["Model: Build, Train, Predict"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8h27rzTcPYJ","executionInfo":{"elapsed":45240,"status":"ok","timestamp":1615875053323,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"38a7af4c-02c1-4074-d26c-f9452ca9930a"},"source":["model = build_model(bert_layer, max_len=160)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 160)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 160)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 160)]        0                                            \n","__________________________________________________________________________________________________\n","keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer[0][1]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            1025        tf.__operators__.getitem[0][0]   \n","==================================================================================================\n","Total params: 335,142,914\n","Trainable params: 335,142,913\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wseNd9QWcPU_","executionInfo":{"elapsed":3881120,"status":"ok","timestamp":1615878889824,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"32676166-afcb-410e-8e4d-96ac1deb6038"},"source":["# Training the model:\n","\n","train_history = model.fit(\n","    train_input, train_labels,\n","    validation_split=0.2,\n","    epochs=1,\n","    batch_size=16\n",")\n","\n","model.save('model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["381/381 [==============================] - 3793s 10s/step - loss: 0.5446 - accuracy: 0.7303 - val_loss: 0.3906 - val_accuracy: 0.8365\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2v43BWZrfzHm"},"source":["test_pred = model.predict(test_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWtynSPd_YBG","executionInfo":{"elapsed":857,"status":"ok","timestamp":1615881379475,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"e4125b9c-03ef-4074-c3c5-22e912fd02f7"},"source":["type(test_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaM-knLdCRpJ","executionInfo":{"elapsed":793,"status":"ok","timestamp":1615881395847,"user":{"displayName":"Dipanjana Lincode","photoUrl":"","userId":"02105401085552057285"},"user_tz":-330},"outputId":"fd747ec4-8a9f-47e2-fa29-1975daa0f17f"},"source":["test_pred[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.70687956], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"UaFO0yWvCUIR"},"source":[""],"execution_count":null,"outputs":[]}]}